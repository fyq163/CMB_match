{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversal validation\n",
    "1. Isna by axis=0\\\n",
    "\\\n",
    "First import the essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks/packages')\n",
    "    !pip install git+https://github.com/keras-team/keras-tuner.git\n",
    "    !pip install autokeras\n",
    "    config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 2} )\n",
    "    sess = tf.Session(config=config)\n",
    "    keras.backend.set_session(sess)\n",
    "else:\n",
    "    path_fill = 'data/2022/filled_trian.csv'\n",
    "    path_raw_train='data/2022/train.csv'\n",
    "    path_A='data/2022/test_A榜.csv'\n",
    "    path_B='data/2022/test_B榜.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import useful_functions as uf\n",
    "import autokeras as ak\n",
    "df_train = pd.read_csv(path_raw_train).head(500)\n",
    "df_train_filled = pd.read_csv(path_fill,index_col=0).head(500)\n",
    "df_test_A = pd.read_csv(path_A).head(500)\n",
    "df_test_B = pd.read_csv(path_B).head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Drop too few columns, optional drop index for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_too_few_variable(dataframe: pd.DataFrame, threshold=0.75, whether_index = False):\n",
    "    total_rows = len(df_test_A.index)\n",
    "    mask_drop = (dataframe.count() / total_rows ) > threshold\n",
    "    dataframe = dataframe.loc[:, mask_drop]\n",
    "    if whether_index:\n",
    "        drop_index = dataframe.isna().sum(axis=1)>=len(dataframe.columns)*threshold\n",
    "        drop_index = [ind for ind in drop_index.index if drop_index[ind]==True]\n",
    "        dataframe.drop(index = drop_index)\n",
    "        return dataframe.drop(index = drop_index)\n",
    "    else:\n",
    "        return dataframe\n",
    "df_train = drop_too_few_variable(df_train,0.75,True)\n",
    "portfolio:list = [df_test_A,df_test_B]\n",
    "for i in range(len(portfolio)):\n",
    "    portfolio[i] = drop_too_few_variable(portfolio[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. step 1, minus 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_col = uf.dynamic_string_col(df_train)\n",
    "df_train,string_col = uf.step1_data_processing(df_train,s_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need try iqr first or fillna first\n",
    "\\\n",
    "\\\n",
    "4.  Fillna, try random_forest, KNN, mode\n",
    "## 3.2 数据集中缺失值从少到多进行排序\n",
    "从缺失值最少的开始填，所以首先需要一个排序，即数据集中缺失值从少到多的一个顺序\n",
    "# 3.3构建新特征矩阵和新标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MON_12_AGV_LVE_ACT_CNT                      0\n",
       "MON_12_ACM_LVE_ACT_CNT                      0\n",
       "MON_12_AGV_ENTR_ACT_CNT                     0\n",
       "MON_12_EXT_SAM_TRSF_IN_AMT                  0\n",
       "LAST_12_MON_DIF_NM_MON_AVG_TRX_AMT_NAV      0\n",
       "LAST_12_MON_MON_AVG_TRX_AMT_NAV             0\n",
       "MON_12_EXT_SAM_AMT                          0\n",
       "MON_12_EXT_SAM_NM_TRSF_OUT_CNT              0\n",
       "MON_12_EXT_SAM_TRSF_OUT_AMT                 0\n",
       "MON_12_ACM_ENTR_ACT_CNT                     0\n",
       "AI_STAR_SCO                                 4\n",
       "COR_KEY_PROD_HLD_NBR                        7\n",
       "WTHR_OPN_ONL_ICO                            7\n",
       "PUB_TO_PRV_TRX_AMT_CUR_YEAR                 9\n",
       "CUR_YEAR_COUNTER_ENCASH_CNT                 9\n",
       "CUR_YEAR_MON_AGV_TRX_CNT                    9\n",
       "CUR_MON_EXT_SAM_CUST_TRSF_OUT_AMT           9\n",
       "CUR_MON_EXT_SAM_CUST_TRSF_IN_AMT            9\n",
       "COUNTER_CUR_YEAR_CNT_AMT                    9\n",
       "REG_DT                                     20\n",
       "ICO_CUR_MON_ACM_TRX_TM                     41\n",
       "ICO_CUR_MON_ACM_TRX_AMT                    41\n",
       "REG_CPT                                    44\n",
       "NB_RCT_3_MON_LGN_TMS_AGV                   44\n",
       "MON_12_ACT_OUT_50_UP_CNT_PTY_QTY           59\n",
       "MON_12_ACT_IN_50_UP_CNT_PTY_QTY            59\n",
       "MON_6_50_UP_ENTR_ACT_CNT                   71\n",
       "MON_6_50_UP_LVE_ACT_CNT                    71\n",
       "NB_CTC_HLD_IDV_AIO_CARD_SITU               80\n",
       "MON_12_TRX_AMT_MAX_AMT_PCTT               115\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sor_by_nan = df_train.isna().sum().sort_values(ascending=True)\n",
    "con = sor_by_nan>0\n",
    "sor_by_nan =sor_by_nan[con].index # index\n",
    "\n",
    "i=10    # loop over all columns with nan \n",
    "to_be_fillc:str = sor_by_nan[i]\n",
    "#---------------- FILL IN ALL ZERO --------------------------------\n",
    "x_tobe_0 = sor_by_nan[sor_by_nan!=to_be_fillc]\n",
    "\n",
    "y_tobe_trained = df_train[df_train[to_be_fillc].notna()][to_be_fillc]\n",
    "tobe_tested_index = df_train[df_train[to_be_fillc].isna()][to_be_fillc].index\n",
    "x_tobe_tested = df_train.loc[tobe_tested_index,x_tobe_0]\n",
    "x_tobe_trained = df_train.loc[y_tobe_trained.index,x_tobe_0]\n",
    "x_tobe_trained.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
