{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversal validation\n",
    "1. Isna by axis=0\\\n",
    "\\\n",
    "First import the essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks/packages')\n",
    "    !pip install git+https://github.com/keras-team/keras-tuner.git\n",
    "    !pip install autokeras\n",
    "    config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 2} )\n",
    "    sess = tf.Session(config=config)\n",
    "    keras.backend.set_session(sess)\n",
    "else:\n",
    "    path_fill = 'data/2022/filled_trian.csv'\n",
    "    path_raw_train='data/2022/train.csv'\n",
    "    path_A='data/2022/test_A榜.csv'\n",
    "    path_B='data/2022/test_B榜.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import useful_functions as uf\n",
    "import autokeras as ak\n",
    "df_train = pd.read_csv(path_raw_train).head(500)\n",
    "df_train_filled = pd.read_csv(path_fill,index_col=0).head(500)\n",
    "df_test_A = pd.read_csv(path_A).head(500)\n",
    "df_test_B = pd.read_csv(path_B).head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn_pandas as sp\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Drop too few columns, optional drop index for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_too_few_variable(dataframe: pd.DataFrame, threshold=0.75, whether_index = False):\n",
    "    total_rows = len(df_test_A.index)\n",
    "    mask_drop = (dataframe.count() / total_rows ) > threshold\n",
    "    dataframe = dataframe.loc[:, mask_drop]\n",
    "    if whether_index:\n",
    "        drop_index = dataframe.isna().sum(axis=1)>=len(dataframe.columns)*threshold\n",
    "        drop_index = [ind for ind in drop_index.index if drop_index[ind]==True]\n",
    "        dataframe.drop(index = drop_index)\n",
    "        return dataframe.drop(index = drop_index)\n",
    "    else:\n",
    "        return dataframe\n",
    "df_train = drop_too_few_variable(df_train,0.75,True)\n",
    "portfolio:list = [df_test_A,df_test_B]\n",
    "for i in range(len(portfolio)):\n",
    "    portfolio[i] = drop_too_few_variable(portfolio[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. step 1, minus 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_col = uf.dynamic_string_col(df_train)\n",
    "df_train,string_col = uf.step1_data_processing(df_train,s_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need try iqr first or fillna first\n",
    "\\\n",
    "Slip into two, nu and not nu\n",
    "\\\n",
    "4.  Fillna, try random_forest, KNN, mode\n",
    "## 3.2 数据集中缺失值从少到多进行排序\n",
    "从缺失值最少的开始填，所以首先需要一个排序，即数据集中缺失值从少到多的一个顺序\n",
    "# 3.3构建新特征矩阵和新标签"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the string col first, fill with mode, then fill with iteraimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(498, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_col = uf.dynamic_string_col(df_train)\n",
    "df_train_str = df_train.loc[:,s_col]\n",
    "impMode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df_train_str = \\\n",
    "    pd.DataFrame(impMode.transform(df_train_str),columns=s_col,index=df_train_str.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sor_by_nan = df_nu.isna().sum().sort_values(ascending=True)\n",
    "\n",
    "con = sor_by_nan>0\n",
    "sor_by_nan =sor_by_nan[con].index # index\n",
    "\n",
    "i=0    # loop over all columns with nan \n",
    "to_be_fillc:str = sor_by_nan[i]\n",
    "x_tobe_0 = sor_by_nan[sor_by_nan!=to_be_fillc]\n",
    "\n",
    "y_tobe_trained = df_train[df_train[to_be_fillc].notna()][to_be_fillc]\n",
    "tobe_tested_index = df_train[df_train[to_be_fillc].isna()][to_be_fillc].index\n",
    "\n",
    "x_tobe_tested = uf.get_numerical_df(df_train.loc[tobe_tested_index,x_tobe_0])\n",
    "x_tobe_trained = uf.get_numerical_df(df_train.loc[y_tobe_trained.index,x_tobe_0])\n",
    "\n",
    "\n",
    "#---------------- FILL IN ALL ZERO x train --------------------------------\n",
    "imp0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "x_tobe_trained=imp0.fit_transform(x_tobe_trained)\n",
    "x_tobe_tested=imp0.transform(x_tobe_tested)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nu = uf.get_numerical_df(df_train)\n",
    "sor_by_nan = df_nu.isna().sum().sort_values(ascending=True)\n",
    "# star with the least missing number\n",
    "con = sor_by_nan>0 # Filter out those with no missing values\n",
    "sor_by_nan =sor_by_nan[con].index # index\n",
    "i=0    # loop over all columns with nan\n",
    "to_be_fillc:str = sor_by_nan[i]\n",
    "x_tobe_0 = sor_by_nan[sor_by_nan!=to_be_fillc]\n",
    "# columns names that are going to be filled woth zero as training data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
