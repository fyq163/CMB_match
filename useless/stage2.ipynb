{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! pip install autokeras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "# import matplotlib.pyplot as plt\n",
    "import useful_functions as uf\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "path_fill = '/workspaces/CMB_match/data/2022/filled_trian.csv'\n",
    "path_train_pure = '/workspaces/CMB_match/data/2022/train.csv'\n",
    "# data/2022/filled_trian.csv\n",
    "df_train_filled = pd.read_csv(path_fill, index_col=0)\n",
    "df_train = pd.read_csv(path_train_pure)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "有序型分类变量：使用LabelEncoder()编码；\n",
    "\n",
    "无序型分类变量：使用独热编码。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "string_col =uf.dynamic_string_col(df_train_filled)\n",
    "\n",
    "opt_col = string_col.copy()\n",
    "\n",
    "df_str=pd.DataFrame()\n",
    "if 'MON_12_CUST_CNT_PTY_ID' in string_col:\n",
    "    # This a Binary Y/N, the training sample has Y only, do not fill with the mode\n",
    "    opt_col.remove('MON_12_CUST_CNT_PTY_ID')\n",
    "    df_str.loc[:,'MON_12_CUST_CNT_PTY_ID'] = df_train_filled['MON_12_CUST_CNT_PTY_ID']\n",
    "    # Direct copy\n",
    "# fill the missing value with mode\n",
    "df_str.loc[:,opt_col] = uf.mode_nan_string(df_train_filled.loc[:, opt_col])\n",
    "## One-hot encoding\n",
    "df_str.loc[:,'SHH_BCK']=df_str.SHH_BCK.astype(str) # it was floated\n",
    "dummies = pd.get_dummies(df_str,dummy_na=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_df_numerical= uf.get_numerical_df(df_train_filled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1 无序分类变量的相关性\n",
    "2 get the correlation matrix of the numerical variables\n",
    "3 save the first column with the lowest missing value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_cols = uf.high_corr_col(df_train_filled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "drop_col = uf.save_n_drop(corr_cols,df_train_filled)\n",
    "test = df_train_filled.drop(drop_col,axis=1)\n",
    "second_corr = test.loc[:,uf.high_corr_col(test)].corr()\n",
    "second_corr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are still four columns i.e. two paris are high correlated variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows,cols = np.where(second_corr>0.8)\n",
    "# gives the position of all correlation value >0.8\n",
    "get_rid_2=list()\n",
    "for i in range(len(rows)):\n",
    "    posi= second_corr.iloc[rows[i],cols[i]]\n",
    "    # rows[i],cols[i] is the position of the element in the matrix\n",
    "    # posi is the correlation value of rows[i] and cols[i]\n",
    "    if posi<0.9990: # type: ignore\n",
    "        col_set = {second_corr.index[rows[i]], second_corr.columns[cols[i]]}\n",
    "        # this is the actual column name\n",
    "        if col_set not in get_rid_2: # because the set disregard the order,\n",
    "            # so we need to check if the set is already in the list,\n",
    "            # the pair with the same two elements\n",
    "            # but different order will be regarded as same set,\n",
    "            get_rid_2.append(col_set)\n",
    "drop_col_2  = list(itertools.chain(*get_rid_2)) # take component out to list\n",
    "# drop_col_2 is the list of column name that need to be dropped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "两遍去，第一遍按前三字一组取最低缺失，第二次按照pair取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rank_df = pd.DataFrame(df_train.loc[:, drop_col_2].isna().sum())\n",
    "#---> index:column name, value: number of missing value\n",
    "rank_df.sort_values([0], ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4 use the drop_col we get to drop again"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(get_rid_2)):# loop in length of the four element list\n",
    "    for col_j in get_rid_2[i]: # col_j is the column name\n",
    "        rank_df.loc[col_j,'pair']=i # add a column of pair mark to rank_df\n",
    "        rank_df.loc[col_j,'col_name']=col_j # add a column of column name to rank_df\n",
    "ndarray=rank_df.groupby('pair')[0].nlargest(1)\n",
    "ndarray\n",
    "# rank_df.loc[] # find the column with the least missing value\n",
    "# df.nlargest()\n",
    "# [col for col in test.columns if col not in ndarray]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows,cols = np.where(second_corr>0.8)\n",
    "# gives the position of all correlation value >0.8\n",
    "get_rid_2=list()\n",
    "for i in range(len(rows)):\n",
    "    posi= second_corr.iloc[rows[i],cols[i]]\n",
    "    # rows[i],cols[i] is the position of the element in the matrix\n",
    "    # posi is the correlation value of rows[i] and cols[i]\n",
    "    if posi<0.9990: # type: ignore\n",
    "        col_set = {second_corr.index[rows[i]], second_corr.columns[cols[i]]}\n",
    "        # this is the actual column name\n",
    "        if col_set not in get_rid_2: # because the set disregard the order,\n",
    "            # so we need to check if the set is already in the list,\n",
    "            # the pair with the same two elements\n",
    "            # but different order will be regarded as same set,\n",
    "            get_rid_2.append(col_set)\n",
    "drop_col_2  = list(itertools.chain(*get_rid_2)) # take component out to list\n",
    "# drop_col_2 is the list of column name that need to be dropped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两遍去，第一遍按前三字一组取最低缺失，第二次按照pair取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EMP_NBR</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLD_DMS_CCY_ACT_NBR</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAST_12_MON_COR_DPS_DAY_AVG_BAL</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUR_MON_COR_DPS_MON_DAY_AVG_BAL</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "EMP_NBR                          106\n",
       "HLD_DMS_CCY_ACT_NBR              114\n",
       "LAST_12_MON_COR_DPS_DAY_AVG_BAL  114\n",
       "CUR_MON_COR_DPS_MON_DAY_AVG_BAL  116"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df = pd.DataFrame(df_train.loc[:, drop_col_2].isna().sum())\n",
    "#---> index:column name, value: number of missing value\n",
    "rank_df.sort_values([0], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4 use the drop_col we get to drop again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pair                                 \n",
       "0.0   HLD_DMS_CCY_ACT_NBR                114\n",
       "1.0   CUR_MON_COR_DPS_MON_DAY_AVG_BAL    116\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(len(get_rid_2)):# loop in length of the four element list\n",
    "    for col_j in get_rid_2[i]: # col_j is the column name\n",
    "        rank_df.loc[col_j,'pair']=i # add a column of pair mark to rank_df\n",
    "        rank_df.loc[col_j,'col_name']=col_j # add a column of column name to rank_df\n",
    "ndarray=rank_df.groupby('pair')[0].nlargest(1)\n",
    "ndarray\n",
    "# rank_df.loc[] # find the column with the least missing value\n",
    "# df.nlargest()\n",
    "# [col for col in test.columns if col not in ndarray]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}